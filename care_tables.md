| **Collaborativeness sub-capabilities** | **Level 1** | **Level 2** | **Level 3**|
|----|-----|---------|------|
| Initiating relationships |Form a goal | Select a partner or group appropriate for a goal | Initiate relationships and group formation appropriate for a goal |
| Establishing shared situational awareness | Individual knowledge of situation | Shared knowledge of a situation  | Common knowledge of a situation |
| Personalized multimodal user interaction | Perception of social cues to infer partner characteristics | Management of social signals to communicate to partner to coordinate effectively | Collaborative strategies based on long term memory of group experiences |
| Collaborative group support | Communicate and respond to otherâ€™s needs | Identify inefficiencies and better solutions to effective coordination and cooperation | Strategies for managing conflict, power asymmetries, hierarchy |
| **Adaptivity sub-capabilities** | | | |
| Learning through interaction | Ask humans for suitable and sufficient feedback | Rich interaction with one human partner | Rich interaction with multiple AI and human partners | 
| Learning how to interact | Predict what human partner knows, wants and needs (ToM) | Anticipate how human reacts in human-agent  collaboration | Anticipate how humans react in larger, mixed teams | 
| Incremental adaptivity | Detect uncertainty of performance due to changing situations, goals and preferences; take suitable action | Predict likely upcoming situations, switching between pre-learned models | Online learning for predicted and surprising changes in situations, goals, and preferences |
| Integrate symbolic constraints during learning | Identify and ask for meaning of new symbols | Learn rich meaning of symbols  | hared meaning and use of symbols |
| **Responsibility sub-capabilities** | | | | 
| Critically examining algorithmic decisions of big data applications on their legal or moral quality | Identifying the grounds on which a decision was reached | Monologically assessing the legal or moral quality of the decision | Engaging in human-machine dialogue about the legal or moral quality of the decision |
| Validating whether legally or morally acceptable behavior is learned | Consistently and completely representing ethical or legal knowledge for validation purposes | Matching the representations with the learned behavior | Improving the learned behavior | 
| Reasoning about the legal or ethical acceptability of intended behavior | Combining reasoning with formalized legal or ethical knowledge with self-interested motivations | Combining reasoning with legal or ethical knowledge extracted from unstructured sources with self-interested motivations | Engaging in human-machine dialogue about the legal or moral quality of the intended behavior |
| **Explainability sub-capabilities** | | | |
| Transferability of shared representations | Within a single domain | Between different domains | Between different domains and tasks |
| Quality of the explanations (metric to be determined) | Partial explanations | Full explanations | User-tailored full explanations |
| Interactive explanations | Instruction generation (speaker model) | Awareness of instructions (listener model) | End-to-end speaker & listener model |